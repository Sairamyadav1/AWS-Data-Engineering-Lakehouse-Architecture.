# AWS Data Engineering Lakehouse Architecture

A production-ready, end-to-end AWS data engineering project implementing a modern Lakehouse architecture using the Bronze-Silver-Gold medallion pattern.

## ğŸ—ï¸ Architecture Overview

This project demonstrates a scalable data lakehouse implementation on AWS, featuring:

- **Bronze Layer**: Raw data ingestion from various sources
- **Silver Layer**: Cleaned and conformed data
- **Gold Layer**: Business-level aggregated data ready for analytics

### Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Sourcesâ”‚
â”‚ (S3, APIs)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        BRONZE LAYER (Raw)           â”‚
â”‚  - Raw data ingestion               â”‚
â”‚  - Schema on read                   â”‚
â”‚  - Immutable storage                â”‚
â”‚  - AWS Glue Crawlers                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼ AWS Glue ETL Jobs
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      SILVER LAYER (Cleaned)         â”‚
â”‚  - Data quality checks              â”‚
â”‚  - Deduplication                    â”‚
â”‚  - Schema enforcement               â”‚
â”‚  - Partitioned by date              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼ AWS Glue ETL Jobs
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GOLD LAYER (Business Ready)       â”‚
â”‚  - Aggregated metrics               â”‚
â”‚  - Business logic applied           â”‚
â”‚  - Optimized for querying           â”‚
â”‚  - Star/Snowflake schema            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Analytics & BI Layer          â”‚
â”‚  - Amazon Athena                     â”‚
â”‚  - AWS QuickSight                    â”‚
â”‚  - Snowflake Integration             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ architecture/
â”‚   â””â”€â”€ architecture-diagram.png      # Detailed architecture diagram
â”œâ”€â”€ glue-scripts/
â”‚   â”œâ”€â”€ bronze/                       # Raw data ingestion scripts
â”‚   â”œâ”€â”€ silver/                       # Data cleaning & transformation
â”‚   â””â”€â”€ gold/                         # Business-level aggregations
â”œâ”€â”€ athena-queries/
â”‚   â””â”€â”€ *.sql                        # SQL queries for data analysis
â”œâ”€â”€ glue-crawlers/
â”‚   â””â”€â”€ crawler-configs/             # Glue Crawler configurations
â”œâ”€â”€ snowflake-integration/
â”‚   â”œâ”€â”€ setup/                       # Snowflake setup scripts
â”‚   â””â”€â”€ queries/                     # Snowflake queries
â”œâ”€â”€ iam-policies/
â”‚   â””â”€â”€ *.json                       # IAM roles and policies
â”œâ”€â”€ sample-data/
â”‚   â””â”€â”€ *.csv                        # Sample datasets for testing
â””â”€â”€ docs/
    â”œâ”€â”€ deployment-guide.md          # Step-by-step deployment
    â”œâ”€â”€ best-practices.md            # Data engineering best practices
    â””â”€â”€ troubleshooting.md           # Common issues and solutions
```

## ğŸš€ Features

- âœ… **Medallion Architecture**: Bronze â†’ Silver â†’ Gold data layers
- âœ… **AWS Glue ETL**: Serverless Spark-based transformations
- âœ… **AWS Glue Data Catalog**: Centralized metadata management
- âœ… **Amazon Athena**: SQL-based data querying
- âœ… **Snowflake Integration**: Cloud data warehouse connectivity
- âœ… **IAM Security**: Least-privilege access controls
- âœ… **Data Quality**: Validation and error handling
- âœ… **Partitioning**: Optimized for query performance
- âœ… **Cost Optimization**: S3 lifecycle policies and resource tagging

## ğŸ› ï¸ Technologies Used

- **Storage**: Amazon S3
- **ETL**: AWS Glue (PySpark)
- **Catalog**: AWS Glue Data Catalog
- **Query Engine**: Amazon Athena
- **Data Warehouse**: Snowflake
- **Orchestration**: AWS Glue Workflows
- **Security**: AWS IAM
- **Monitoring**: AWS CloudWatch

## ğŸ“‹ Prerequisites

- AWS Account with appropriate permissions
- AWS CLI configured
- Python 3.8+ (for local testing)
- Snowflake account (optional, for integration)
- Basic understanding of:
  - AWS services (S3, Glue, Athena)
  - SQL
  - PySpark
  - Data engineering concepts

## ğŸ¯ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/Sairamyadav1/AWS-Data-Engineering-Lakehouse-Architecture.git
cd AWS-Data-Engineering-Lakehouse-Architecture
```

### 2. Set Up AWS Resources

```bash
# Create S3 buckets for each layer
aws s3 mb s3://your-bronze-bucket
aws s3 mb s3://your-silver-bucket
aws s3 mb s3://your-gold-bucket

# Upload sample data
aws s3 cp sample-data/ s3://your-bronze-bucket/raw-data/ --recursive
```

### 3. Create IAM Roles

Apply the IAM policies from the `iam-policies/` directory:

```bash
aws iam create-role --role-name GlueETLRole --assume-role-policy-document file://iam-policies/glue-trust-policy.json
aws iam put-role-policy --role-name GlueETLRole --policy-name GlueS3Access --policy-document file://iam-policies/glue-s3-policy.json
```

### 4. Deploy Glue Crawlers

```bash
# Create crawlers for each layer
aws glue create-crawler --cli-input-json file://glue-crawlers/bronze-crawler.json
aws glue create-crawler --cli-input-json file://glue-crawlers/silver-crawler.json
aws glue create-crawler --cli-input-json file://glue-crawlers/gold-crawler.json
```

### 5. Run ETL Jobs

```bash
# Upload Glue scripts to S3
aws s3 cp glue-scripts/ s3://your-scripts-bucket/glue-scripts/ --recursive

# Create and run Glue jobs
aws glue create-job --cli-input-json file://glue-scripts/bronze/job-config.json
aws glue start-job-run --job-name bronze-ingestion-job
```

### 6. Query with Athena

Use the SQL queries in `athena-queries/` to analyze your data:

```sql
-- Example: Query gold layer data
SELECT * FROM gold_db.sales_summary
WHERE year = 2024
LIMIT 10;
```

## ğŸ“Š Data Flow

1. **Ingestion (Bronze)**
   - Raw data lands in S3 bronze bucket
   - Glue Crawler catalogs the schema
   - Data stored in original format (CSV, JSON, Parquet)

2. **Transformation (Silver)**
   - Glue ETL job reads from bronze
   - Applies data quality rules
   - Deduplicates records
   - Standardizes formats
   - Writes cleaned data to silver bucket

3. **Aggregation (Gold)**
   - Glue ETL job reads from silver
   - Applies business logic
   - Creates aggregated views
   - Optimizes for analytics queries
   - Writes to gold bucket in Parquet format

4. **Analytics**
   - Athena queries gold layer tables
   - QuickSight dashboards visualize data
   - Snowflake integration for advanced analytics

## ğŸ” Security Best Practices

- **Encryption**: All S3 buckets use AES-256 encryption
- **IAM Roles**: Least-privilege access for Glue jobs
- **VPC**: Glue jobs run in private subnets (optional)
- **Secrets Manager**: Database credentials stored securely
- **CloudTrail**: All API calls are logged
- **S3 Bucket Policies**: Restrict access by IP/VPC

## ğŸ’° Cost Optimization

- Use S3 Intelligent-Tiering for cost savings
- Partition data by date to reduce Athena scan costs
- Use Glue bookmarks to avoid reprocessing data
- Set Glue job timeout limits
- Use Spot instances for non-critical workloads
- Implement data lifecycle policies

## ğŸ“ˆ Monitoring & Logging

- **CloudWatch Metrics**: Monitor Glue job execution
- **CloudWatch Logs**: Debug ETL failures
- **Glue Job Metrics**: Track DPU usage and costs
- **Athena Query History**: Analyze query performance
- **S3 Access Logs**: Audit data access patterns

## ğŸ§ª Testing

```bash
# Run unit tests for Glue scripts
python -m pytest tests/

# Validate data quality
python scripts/validate_data_quality.py
```

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¨â€ğŸ’» Author

**Sai Ram Yadav**

- GitHub: [@Sairamyadav1](https://github.com/Sairamyadav1)

## ğŸ™ Acknowledgments

- AWS Documentation
- Data Engineering Community
- Medallion Architecture Pattern

## ğŸ“š Additional Resources

- [AWS Glue Developer Guide](https://docs.aws.amazon.com/glue/)
- [Amazon Athena User Guide](https://docs.aws.amazon.com/athena/)
- [Lakehouse Architecture Whitepaper](https://www.databricks.com/lakehouse)
- [Data Engineering Best Practices](https://aws.amazon.com/big-data/datalakes-and-analytics/)

---

â­ **Star this repository if you find it helpful!**